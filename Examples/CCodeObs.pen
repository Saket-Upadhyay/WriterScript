#include <openssl/e_os2h> #include <stringh> #include <asserth> size_t SHA3_absorb(uint64_t A[5][5],
const unsigned char *inp size_t,
len size_t r); void SHA3_squeeze(uint64_t,
A[5][5] unsigned char *out size_t,
len size_t r); #if !defined(KECCAK1600_ASM),
|| !defined(SELFTEST) /* * Choose,
some sensible defaults */ #if,
!defined(KECCAK_REF) && !defined(KECCAK_1X) && !defined(KECCAK_1X_ALT),
&& \ !defined(KECCAK_2X) && !defined(KECCAK_INPLACE),
# define KECCAK_2X /* default,
to KECCAK_2X variant */ #endif,
#if defined(__i386) || defined(__i386__) || defined(_M_IX86) ||,
\ (defined(__x86_64) && !defined(__BMI__)) || defined(_M_X64) || \ defined(__mips),
|| defined(__riscv) || defined(__s390__) ||,
\ defined(__EMSCRIPTEN__) /* * These,
don't have "and with complement",
instruction so minimize amount *,
of "not"-s Implemented only in,
the [default] KECCAK_2X variant */,
# define KECCAK_COMPLEMENTING_TRANSFORM #endif #if,
defined(__x86_64__) || defined(__aarch64__) || \,
defined(__mips64) || defined(__ia64) || \ (defined(__VMS) && !defined(__vax)) /*,
* These are available even,
in ILP32 flavours but even,
then they are * capable,
of performing 64-bit operations as,
efficiently as in *P64 *,
Since it's not given that,
we can use sizeof(void *),
just shunt it */ #,
define BIT_INTERLEAVE (0) #else #,
define BIT_INTERLEAVE (sizeof(void *) <,
8) #endif #define ROL32(a offset) (((a) << (offset)) |,
((a) >> ((32 - (offset)),
& 31))) static uint64_t ROL64(uint64_t,
val int offset) { if,
(offset == 0) { return,
val; } else if (!BIT_INTERLEAVE),
{ return (val << offset),
| (val >> (64-offset)); },
else { uint32_t hi =,
(uint32_t)(val >> 32) lo =,
(uint32_t)val; if (offset & 1),
{ uint32_t tmp = hi; offset >>= 1; hi,
= ROL32(lo offset); lo =,
ROL32(tmp offset + 1); },
else { offset >>= 1;,
lo = ROL32(lo offset); hi,
= ROL32(hi offset); } return,
((uint64_t)hi << 32) | lo;,
} } static const unsigned,
char rhotates[5][5] = { {,
0 1 62 28 27,
} { 36 44 6,
55 20 } { 3,
10 43 25 39 },
{ 41 45 15 21 8 } { 18,
2 61 56 14 },
}; static const uint64_t iotas[],
= { BIT_INTERLEAVE ? 0x0000000000000001ULL,
: 0x0000000000000001ULL BIT_INTERLEAVE ? 0x0000008900000000ULL,
: 0x0000000000008082ULL BIT_INTERLEAVE ? 0x8000008b00000000ULL,
: 0x800000000000808aULL BIT_INTERLEAVE ? 0x8000808000000000ULL,
: 0x8000000080008000ULL BIT_INTERLEAVE ? 0x0000008b00000001ULL,
: 0x000000000000808bULL BIT_INTERLEAVE ? 0x0000800000000001ULL,
: 0x0000000080000001ULL BIT_INTERLEAVE ? 0x8000808800000001ULL,
: 0x8000000080008081ULL BIT_INTERLEAVE ? 0x8000008200000001ULL,
: 0x8000000000008009ULL BIT_INTERLEAVE ? 0x0000000b00000000ULL,
: 0x000000000000008aULL BIT_INTERLEAVE ? 0x0000000a00000000ULL,
: 0x0000000000000088ULL BIT_INTERLEAVE ? 0x0000808200000001ULL : 0x0000000080008009ULL BIT_INTERLEAVE ?,
0x0000800300000000ULL : 0x000000008000000aULL BIT_INTERLEAVE ?,
0x0000808b00000001ULL : 0x000000008000808bULL BIT_INTERLEAVE ?,
0x8000000b00000001ULL : 0x800000000000008bULL BIT_INTERLEAVE ?,
0x8000008a00000001ULL : 0x8000000000008089ULL BIT_INTERLEAVE ?,
0x8000008100000001ULL : 0x8000000000008003ULL BIT_INTERLEAVE ?,
0x8000008100000000ULL : 0x8000000000008002ULL BIT_INTERLEAVE ?,
0x8000000800000000ULL : 0x8000000000000080ULL BIT_INTERLEAVE ?,
0x0000008300000000ULL : 0x000000000000800aULL BIT_INTERLEAVE ?,
0x8000800300000000ULL : 0x800000008000000aULL BIT_INTERLEAVE ?,
0x8000808800000001ULL : 0x8000000080008081ULL BIT_INTERLEAVE ?,
0x8000008800000000ULL : 0x8000000000008080ULL BIT_INTERLEAVE ? 0x0000800000000001ULL : 0x0000000080000001ULL BIT_INTERLEAVE,
? 0x8000808200000000ULL : 0x8000000080008008ULL };,
#if defined(KECCAK_REF) /* * This,
is straightforward or "maximum clarity",
implementation aiming * to resemble,
section 32 of the FIPS,
PUB 202 "SHA-3 Standard: *,
Permutation-Based Hash and Extendible-Output Functions",
as much as * possible,
With one caveat Because of,
the way C stores matrices,
* references to A[xy] in the specification are presented,
as A[y][x] * Implementation unrolls,
inner x-loops so that modulo,
5 operations are * explicitly,
pre-computed */ static void Theta(uint64_t,
A[5][5]) { uint64_t C[5] D[5];,
size_t y; C[0] = A[0][0];,
C[1] = A[0][1]; C[2] =,
A[0][2]; C[3] = A[0][3]; C[4],
= A[0][4]; for (y =,
1; y < 5; y++),
{ C[0] ^= A[y][0]; C[1],
^= A[y][1]; C[2] ^= A[y][2];,
C[3] ^= A[y][3]; C[4] ^= A[y][4]; } D[0] =,
ROL64(C[1] 1) ^ C[4]; D[1],
= ROL64(C[2] 1) ^ C[0];,
D[2] = ROL64(C[3] 1) ^,
C[1]; D[3] = ROL64(C[4] 1),
^ C[2]; D[4] = ROL64(C[0],
1) ^ C[3]; for (y,
= 0; y < 5;,
y++) { A[y][0] ^= D[0];,
A[y][1] ^= D[1]; A[y][2] ^=,
D[2]; A[y][3] ^= D[3]; A[y][4],
^= D[4]; } } static,
void Rho(uint64_t A[5][5]) { size_t y; for (y =,
0; y < 5; y++),
{ A[y][0] = ROL64(A[y][0] rhotates[y][0]);,
A[y][1] = ROL64(A[y][1] rhotates[y][1]); A[y][2],
= ROL64(A[y][2] rhotates[y][2]); A[y][3] =,
ROL64(A[y][3] rhotates[y][3]); A[y][4] = ROL64(A[y][4],
rhotates[y][4]); } } static void,
Pi(uint64_t A[5][5]) { uint64_t T[5][5];,
/* * T = A,
* A[y][x] = T[x][(3*y+x)%5] */,
memcpy(T A sizeof(T)); A[0][0] =,
T[0][0]; A[0][1] = T[1][1]; A[0][2],
= T[2][2]; A[0][3] = T[3][3]; A[0][4] = T[4][4]; A[1][0],
= T[0][3]; A[1][1] = T[1][4];,
A[1][2] = T[2][0]; A[1][3] =,
T[3][1]; A[1][4] = T[4][2]; A[2][0],
= T[0][1]; A[2][1] = T[1][2];,
A[2][2] = T[2][3]; A[2][3] =,
T[3][4]; A[2][4] = T[4][0]; A[3][0],
= T[0][4]; A[3][1] = T[1][0];,
A[3][2] = T[2][1]; A[3][3] =,
T[3][2]; A[3][4] = T[4][3]; A[4][0],
= T[0][2]; A[4][1] = T[1][3];,
A[4][2] = T[2][4]; A[4][3] =,
T[3][0]; A[4][4] = T[4][1]; } static void Chi(uint64_t A[5][5]),
{ uint64_t C[5]; size_t y;,
for (y = 0; y,
< 5; y++) { C[0],
= A[y][0] ^ (~A[y][1] &,
A[y][2]); C[1] = A[y][1] ^,
(~A[y][2] & A[y][3]); C[2] =,
A[y][2] ^ (~A[y][3] & A[y][4]);,
C[3] = A[y][3] ^ (~A[y][4],
& A[y][0]); C[4] = A[y][4],
^ (~A[y][0] & A[y][1]); A[y][0],
= C[0]; A[y][1] = C[1]; A[y][2] = C[2]; A[y][3],
= C[3]; A[y][4] = C[4];,
} } static void Iota(uint64_t,
A[5][5] size_t i) { assert(i,
< (sizeof(iotas) / sizeof(iotas[0]))); A[0][0],
^= iotas[i]; } static void,
KeccakF1600(uint64_t A[5][5]) { size_t i;,
for (i = 0; i,
< 24; i++) { Theta(A);,
Rho(A); Pi(A); Chi(A); Iota(A i);,
} } #elif defined(KECCAK_1X) /* * This implementation is,
optimization of above code featuring,
unroll * of even y-loops,
their fusion and code motion,
It also minimizes * temporary,
storage Compiler would normally do,
all these things for * you purpose of manual,
optimization is to provide "unobscured",
* reference for assembly implementation,
[in case this approach is,
* chosen for implementation on,
some platform] In the nutshell,
it's * equivalent of "plane-per-plane processing" approach discussed in,
* section 24 of "Keccak,
implementation overview" */ static void,
Round(uint64_t A[5][5] size_t i) {,
uint64_t C[5] E[2]; /* registers,
*/ uint64_t D[5] T[2][5]; /*,
memory */ assert(i < (sizeof(iotas),
/ sizeof(iotas[0]))); C[0] = A[0][0],
^ A[1][0] ^ A[2][0] ^,
A[3][0] ^ A[4][0]; C[1] = A[0][1] ^ A[1][1] ^,
A[2][1] ^ A[3][1] ^ A[4][1]; C[2] = A[0][2] ^ A[1][2],
^ A[2][2] ^ A[3][2] ^ A[4][2]; C[3] = A[0][3] ^,
A[1][3] ^ A[2][3] ^ A[3][3] ^ A[4][3]; C[4] = A[0][4],
^ A[1][4] ^ A[2][4] ^ A[3][4] ^ A[4][4]; #if defined(__arm__),
D[1] = E[0] = ROL64(C[2] 1) ^ C[0]; D[4] =,
E[1] = ROL64(C[0] 1) ^ C[3]; D[0] = C[0] =,
ROL64(C[1] 1) ^ C[4]; D[2] = C[1] = ROL64(C[3] 1),
^ C[1]; D[3] = C[2] = ROL64(C[4] 1) ^ C[2];,
T[0][0] = A[3][0] ^ C[0]; /* borrow T[0][0] */ T[0][1],
= A[0][1] ^ E[0]; /* D[1] */ T[0][2] = A[0][2],
^ C[1]; /* D[2] */ T[0][3] = A[0][3] ^ C[2];,
/* D[3] */ T[0][4] = A[0][4] ^ E[1]; /* D[4],
*/ C[3] = ROL64(A[3][3] ^ C[2] rhotates[3][3]); /* D[3] */,
C[4] = ROL64(A[4][4] ^ E[1] rhotates[4][4]); /* D[4] */ C[0],
= A[0][0] ^ C[0]; /* rotate by 0 */ /*,
D[0] */ C[2] = ROL64(A[2][2] ^ C[1] rhotates[2][2]); /* D[2],
*/ C[1] = ROL64(A[1][1] ^ E[0] rhotates[1][1]); /* D[1] */,
#else D[0] = ROL64(C[1] 1) ^,
C[4]; D[1] = ROL64(C[2] 1) ^ C[0]; D[2],
= ROL64(C[3] 1) ^ C[1]; D[3] = ROL64(C[4] 1),
^ C[2]; D[4] = ROL64(C[0] 1),
^ C[3]; T[0][0] = A[3][0] ^ D[0]; /* borrow,
T[0][0] */ T[0][1] = A[0][1] ^,
D[1]; T[0][2] = A[0][2] ^ D[2];,
T[0][3] = A[0][3] ^ D[3]; T[0][4] = A[0][4] ^,
D[4]; C[0] = A[0][0] ^,
D[0]; /* rotate by 0,
*/ C[1] = ROL64(A[1][1] ^ D[1] rhotates[1][1]); C[2] =,
ROL64(A[2][2] ^ D[2] rhotates[2][2]); C[3] =,
ROL64(A[3][3] ^ D[3] rhotates[3][3]); C[4] =,
ROL64(A[4][4] ^ D[4] rhotates[4][4]); #endif A[0][0],
= C[0] ^ (~C[1] & C[2]) ^ iotas[i]; A[0][1],
= C[1] ^ (~C[2] & C[3]);,
A[0][2] = C[2] ^ (~C[3] &,
C[4]); A[0][3] = C[3] ^ (~C[4],
& C[0]); A[0][4] = C[4] ^,
(~C[0] & C[1]); T[1][0] = A[1][0],
^ (C[3] = D[0]); T[1][1] = A[2][1] ^ (C[4],
= D[1]); /* borrow T[1][1] */,
T[1][2] = A[1][2] ^ (E[0] = D[2]); T[1][3] =,
A[1][3] ^ (E[1] = D[3]); T[1][4],
= A[2][4] ^ (C[2] = D[4]);,
/* borrow T[1][4] */ C[0] =,
ROL64(T[0][3] rhotates[0][3]); C[1] = ROL64(A[1][4] ^ C[2] rhotates[1][4]); /*,
D[4] */ C[2] = ROL64(A[2][0] ^,
C[3] rhotates[2][0]); /* D[0] */ C[3],
= ROL64(A[3][1] ^ C[4] rhotates[3][1]); /*,
D[1] */ C[4] = ROL64(A[4][2] ^,
E[0] rhotates[4][2]); /* D[2] */ A[1][0] = C[0] ^,
(~C[1] & C[2]); A[1][1] = C[1],
^ (~C[2] & C[3]); A[1][2] =,
C[2] ^ (~C[3] & C[4]); A[1][3],
= C[3] ^ (~C[4] & C[0]);,
A[1][4] = C[4] ^ (~C[0] &,
C[1]); C[0] = ROL64(T[0][1] rhotates[0][1]); C[1] = ROL64(T[1][2] rhotates[1][2]);,
C[2] = ROL64(A[2][3] ^ D[3],
rhotates[2][3]); C[3] = ROL64(A[3][4] ^ D[4] rhotates[3][4]); C[4] =,
ROL64(A[4][0] ^ D[0] rhotates[4][0]); A[2][0] = C[0] ^ (~C[1],
& C[2]); A[2][1] = C[1] ^,
(~C[2] & C[3]); A[2][2] = C[2],
^ (~C[3] & C[4]); A[2][3] =,
C[3] ^ (~C[4] & C[0]); A[2][4],
= C[4] ^ (~C[0] & C[1]);,
C[0] = ROL64(T[0][4] rhotates[0][4]); C[1] = ROL64(T[1][0] rhotates[1][0]); C[2],
= ROL64(T[1][1] rhotates[2][1]); /* originally A[2][1],
*/ C[3] = ROL64(A[3][2] ^ D[2],
rhotates[3][2]); C[4] = ROL64(A[4][3] ^ D[3] rhotates[4][3]); A[3][0] =,
C[0] ^ (~C[1] & C[2]);,
A[3][1] = C[1] ^ (~C[2],
& C[3]); A[3][2] = C[2],
^ (~C[3] & C[4]); A[3][3],
= C[3] ^ (~C[4] & C[0]); A[3][4] = C[4],
^ (~C[0] & C[1]); C[0],
= ROL64(T[0][2] rhotates[0][2]); C[1] =,
ROL64(T[1][3] rhotates[1][3]); C[2] = ROL64(T[1][4] rhotates[2][4]); /* originally A[2][4],
*/ C[3] = ROL64(T[0][0] rhotates[3][0]); /*,
originally A[3][0] */ C[4] = ROL64(A[4][1],
^ D[1] rhotates[4][1]); A[4][0] = C[0],
^ (~C[1] & C[2]); A[4][1] = C[1] ^ (~C[2],
& C[3]); A[4][2] = C[2] ^ (~C[3] & C[4]); A[4][3],
= C[3] ^ (~C[4] & C[0]); A[4][4] = C[4] ^,
(~C[0] & C[1]); } static void KeccakF1600(uint64_t A[5][5]) { size_t,
i; for (i = 0; i < 24; i++) {,
Round(A i); } } #elif defined(KECCAK_1X_ALT) /* * This is,
variant of above KECCAK_1X that reduces requirement for * temporary,
storage even further but at cost of more updates to,
A[][] * It's less suitable if A[][] is memory bound,
but better if it's * register bound */ static void,
Round(uint64_t A[5][5] size_t i) { uint64_t C[5] D[5]; assert(i <,
(sizeof(iotas) / sizeof(iotas[0]))); C[0] = A[0][0] ^ A[1][0] ^ A[2][0],
^ A[3][0] ^ A[4][0]; C[1] = A[0][1] ^ A[1][1] ^,
A[2][1] ^ A[3][1] ^ A[4][1]; C[2] = A[0][2] ^ A[1][2],
^ A[2][2] ^ A[3][2] ^ A[4][2]; C[3] = A[0][3] ^,
A[1][3] ^ A[2][3] ^ A[3][3] ^ A[4][3]; C[4] = A[0][4],
^ A[1][4] ^ A[2][4] ^ A[3][4] ^ A[4][4]; D[1] =,
C[0] ^ ROL64(C[2] 1); D[2] = C[1] ^ ROL64(C[3] 1);,
D[3] = C[2] ^= ROL64(C[4] 1); D[4] = C[3],
^= ROL64(C[0] 1); D[0] = C[4] ^= ROL64(C[1] 1); A[0][1] ^= D[1];,
A[1][1] ^= D[1]; A[2][1] ^= D[1]; A[3][1] ^= D[1];,
A[4][1] ^= D[1]; A[0][2] ^= D[2]; A[1][2] ^= D[2]; A[2][2] ^= D[2];,
A[3][2] ^= D[2]; A[4][2] ^= D[2]; A[0][3] ^= C[2];,
A[1][3] ^= C[2]; A[2][3] ^= C[2]; A[3][3] ^= C[2]; A[4][3] ^= C[2];,
A[0][4] ^= C[3]; A[1][4] ^= C[3]; A[2][4] ^= C[3];,
A[3][4] ^= C[3]; A[4][4] ^= C[3]; A[0][0] ^= C[4]; A[1][0] ^= C[4];,
A[2][0] ^= C[4]; A[3][0] ^= C[4]; A[4][0] ^= C[4];,
C[1] = A[0][1]; C[2] = A[0][2]; C[3] = A[0][3]; C[4] = A[0][4];,
A[0][1] = ROL64(A[1][1] rhotates[1][1]); A[0][2] = ROL64(A[2][2] rhotates[2][2]); A[0][3],
= ROL64(A[3][3] rhotates[3][3]); A[0][4] = ROL64(A[4][4] rhotates[4][4]); A[1][1] = ROL64(A[1][4] rhotates[1][4]); A[2][2],
= ROL64(A[2][3] rhotates[2][3]); A[3][3] = ROL64(A[3][2] rhotates[3][2]); A[4][4] =,
ROL64(A[4][1] rhotates[4][1]); A[1][4] = ROL64(A[4][2] rhotates[4][2]); A[2][3] = ROL64(A[3][4] rhotates[3][4]); A[3][2] =,
ROL64(A[2][1] rhotates[2][1]); A[4][1] = ROL64(A[1][3] rhotates[1][3]); A[4][2] = ROL64(A[2][4],
rhotates[2][4]); A[3][4] = ROL64(A[4][3] rhotates[4][3]); A[2][1] = ROL64(A[1][2] rhotates[1][2]); A[1][3] = ROL64(A[3][1],
rhotates[3][1]); A[2][4] = ROL64(A[4][0] rhotates[4][0]); A[4][3] = ROL64(A[3][0] rhotates[3][0]);,
A[1][2] = ROL64(A[2][0] rhotates[2][0]); A[3][1] = ROL64(A[1][0] rhotates[1][0]); A[1][0] = ROL64(C[3] rhotates[0][3]);,
A[2][0] = ROL64(C[1] rhotates[0][1]); A[3][0] = ROL64(C[4] rhotates[0][4]); A[4][0],
= ROL64(C[2] rhotates[0][2]); C[0] = A[0][0]; C[1] = A[1][0]; D[0] = A[0][1];,
D[1] = A[1][1]; A[0][0] ^= (~A[0][1] & A[0][2]); A[1][0],
^= (~A[1][1] & A[1][2]); A[0][1] ^= (~A[0][2] & A[0][3]); A[1][1] ^= (~A[1][2],
& A[1][3]); A[0][2] ^= (~A[0][3] & A[0][4]); A[1][2] ^=,
(~A[1][3] & A[1][4]); A[0][3] ^= (~A[0][4] & C[0]); A[1][3] ^= (~A[1][4] &,
C[1]); A[0][4] ^= (~C[0] & D[0]); A[1][4] ^= (~C[1],
& D[1]); C[2] = A[2][0]; C[3] = A[3][0]; D[2] = A[2][1]; D[3],
= A[3][1]; A[2][0] ^= (~A[2][1] & A[2][2]); A[3][0] ^=,
(~A[3][1] & A[3][2]); A[2][1] ^= (~A[2][2] & A[2][3]); A[3][1] ^= (~A[3][2] &,
A[3][3]); A[2][2] ^= (~A[2][3] & A[2][4]); A[3][2] ^= (~A[3][3],
& A[3][4]); A[2][3] ^= (~A[2][4] & C[2]); A[3][3] ^= (~A[3][4] & C[3]);,
A[2][4] ^= (~C[2] & D[2]); A[3][4] ^= (~C[3] &,
D[3]); C[4] = A[4][0]; D[4] = A[4][1]; A[4][0] ^= (~A[4][1] & A[4][2]);,
A[4][1] ^= (~A[4][2] & A[4][3]); A[4][2] ^= (~A[4][3] &,
A[4][4]); A[4][3] ^= (~A[4][4] &,
C[4]); A[4][4] ^= (~C[4] &,
D[4]); A[0][0] ^= iotas[i]; },
static void KeccakF1600(uint64_t A[5][5]) {,
size_t i; for (i =,
0; i < 24; i++),
{ Round(A i); } },
#elif defined(KECCAK_2X) /* * This,
implementation is variant of KECCAK_1X,
above with outer-most * round,
loop unrolled twice This allows to take temporary storage * out of,
